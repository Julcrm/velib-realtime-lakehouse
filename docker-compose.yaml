services:
  # --- SERVICE 1 : Spark ---
  my-spark-project:
    build: .
    restart: always
    ports:
      - "4000:4000"
    environment:
      - SPARK_EXTRA_CLASSPATH=/opt/spark/jars/*
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - S3_ENDPOINT_URL=${S3_ENDPOINT_URL}
    networks:
      - coolify

  # --- SERVICE 2 : DAGSTER ---
  dagster-platform:
    build: .
    restart: always
    ports:
      - '3000:3000'
    environment:
      DAGSTER_POSTGRES_USER: '${DAGSTER_POSTGRES_USER}'
      DAGSTER_POSTGRES_PASSWORD: '${DAGSTER_POSTGRES_PASSWORD}'
      DAGSTER_POSTGRES_DB: '${DAGSTER_POSTGRES_DB}'
      DAGSTER_POSTGRES_HOST: '${DAGSTER_POSTGRES_HOST}'
      DAGSTER_HOME: /opt/dagster/dagster_home
      AWS_ACCESS_KEY_ID: '${AWS_ACCESS_KEY_ID}'
      AWS_SECRET_ACCESS_KEY: '${AWS_SECRET_ACCESS_KEY}'
      S3_ENDPOINT_URL: '${S3_ENDPOINT_URL}'
    volumes:
      - 'dagster_home:/opt/dagster/dagster_home'
      - 'dagster_temp:/tmp'
    networks:
      - coolify
    command: >
      sh -c "
      echo 'Génération des fichiers de configuration...' &&
      mkdir -p /opt/dagster/dagster_home &&
      echo 'storage:\n  postgres:\n    postgres_db:\n      username: {env: DAGSTER_POSTGRES_USER}\n      password: {env: DAGSTER_POSTGRES_PASSWORD}\n      hostname: {env: DAGSTER_POSTGRES_HOST}\n      db_name: {env: DAGSTER_POSTGRES_DB}\n      port: 5432\n' > /opt/dagster/dagster_home/dagster.yaml &&
      echo 'load_from:\n  - grpc_server:\n      host: my-spark-project\n      port: 4000\n      location_name: \"spark_project\"' > /opt/dagster/dagster_home/workspace.yaml &&
      echo 'Lancement du Webserver et du Daemon...' &&
      dagster-webserver -h 0.0.0.0 -p 3000 -w /opt/dagster/dagster_home/workspace.yaml &
      dagster-daemon run -w /opt/dagster/dagster_home/workspace.yaml"

networks:
  coolify:
    external: true

volumes:
  dagster_home:
  dagster_temp: