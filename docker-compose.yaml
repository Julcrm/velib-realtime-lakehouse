services:
  # --- SERVICE 1 : Spark ---
  my-spark-project:
    build: .
    restart: always
    ports:
      - "4000:4000"
    environment:
      - SPARK_EXTRA_CLASSPATH=/opt/spark/jars/*
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - S3_ENDPOINT_URL=${S3_ENDPOINT_URL}
    networks:
      - coolify

  # --- SERVICE 2 : DAGSTER ---
  dagster-platform:
    build: .
    restart: always
    ports:
      - '3000:3000'
    environment:
      DAGSTER_POSTGRES_USER: '${DAGSTER_POSTGRES_USER}'
      DAGSTER_POSTGRES_PASSWORD: '${DAGSTER_POSTGRES_PASSWORD}'
      DAGSTER_POSTGRES_DB: '${DAGSTER_POSTGRES_DB}'
      DAGSTER_POSTGRES_HOST: '${DAGSTER_POSTGRES_HOST}'
      DAGSTER_HOME: /opt/dagster/dagster_home
      AWS_ACCESS_KEY_ID: '${AWS_ACCESS_KEY_ID}'
      AWS_SECRET_ACCESS_KEY: '${AWS_SECRET_ACCESS_KEY}'
      S3_ENDPOINT_URL: '${S3_ENDPOINT_URL}'
    volumes:
      - 'dagster_home:/opt/dagster/dagster_home'
      - 'dagster_temp:/tmp'
    networks:
      - coolify
    command: >
      sh -c "
      dagster-webserver -h 0.0.0.0 -p 3000 -w /opt/dagster/dagster_home/workspace.yaml &
      dagster-daemon run -w /opt/dagster/dagster_home/workspace.yaml"

networks:
  coolify:
    external: true

volumes:
  dagster_home:
  dagster_temp: